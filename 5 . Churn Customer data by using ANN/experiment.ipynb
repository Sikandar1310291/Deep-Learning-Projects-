{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a8df163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "899d2661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3caf66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=['RowNumber' , 'CustomerId' , 'Exited'])\n",
    "y = data['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ebf5b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Surname  CreditScore Geography  Gender  Age  Tenure    Balance  \\\n",
       "0  Hargrave          619    France  Female   42       2       0.00   \n",
       "1      Hill          608     Spain  Female   41       1   83807.86   \n",
       "2      Onio          502    France  Female   42       8  159660.80   \n",
       "3      Boni          699    France  Female   39       1       0.00   \n",
       "4  Mitchell          850     Spain  Female   43       2  125510.82   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0              1          1               1        101348.88  \n",
       "1              1          0               1        112542.58  \n",
       "2              3          1               0        113931.57  \n",
       "3              2          0               0         93826.63  \n",
       "4              1          1               1         79084.10  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1287d70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data types:\n",
      "Geography    object\n",
      "Gender       object\n",
      "dtype: object\n",
      "\n",
      "Sample data:\n",
      "  Geography  Gender\n",
      "0    France  Female\n",
      "1     Spain  Female\n",
      "2    France  Female\n",
      "3    France  Female\n",
      "4     Spain  Female\n",
      "\n",
      "Object columns found: ['Geography', 'Gender']\n",
      "\n",
      "Encoding Geography: ['France' 'Spain' 'Germany']\n",
      "  ✓ Saved classes: ['France' 'Germany' 'Spain']\n",
      "\n",
      "Encoding Gender: ['Female' 'Male']\n",
      "  ✓ Saved classes: ['Female' 'Male']\n",
      "\n",
      "✓✓✓ Total encoders saved: 2\n",
      "\n",
      "=== VERIFICATION ===\n",
      "Geography: ['France' 'Germany' 'Spain']\n",
      "Gender: ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: FRESH data load karo (re-read the CSV)\n",
    "df = pd.read_csv('Churn_Modelling.csv')  # ← Original file path\n",
    "\n",
    "# Step 2: Check original data\n",
    "print(\"Original data types:\")\n",
    "print(df[['Geography', 'Gender']].dtypes)\n",
    "print(\"\\nSample data:\")\n",
    "print(df[['Geography', 'Gender']].head())\n",
    "\n",
    "# Step 3: Create x (DON'T use previously encoded x)\n",
    "x = df.drop(['Exited', 'RowNumber', 'CustomerId', 'Surname'], axis=1, errors='ignore')\n",
    "y = df['Exited']\n",
    "\n",
    "# Step 4: Check object columns\n",
    "object_cols = x.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nObject columns found: {object_cols}\")\n",
    "\n",
    "# Step 5: Encode\n",
    "LabelEncoder_dict1 = {}\n",
    "\n",
    "for col in object_cols:\n",
    "    le = LabelEncoder()\n",
    "    print(f\"\\nEncoding {col}: {x[col].unique()}\")\n",
    "    x[col] = le.fit_transform(x[col])\n",
    "    LabelEncoder_dict1[col] = le\n",
    "    print(f\"  ✓ Saved classes: {le.classes_}\")\n",
    "\n",
    "# Step 6: Save\n",
    "with open('LabelEncoder_file1.pkl', 'wb') as file:\n",
    "    pickle.dump(LabelEncoder_dict1, file)\n",
    "\n",
    "print(f\"\\n✓✓✓ Total encoders saved: {len(LabelEncoder_dict1)}\")\n",
    "\n",
    "# Step 7: Verify immediately\n",
    "with open('LabelEncoder_file1.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)\n",
    "    print(\"\\n=== VERIFICATION ===\")\n",
    "    for col, encoder in test.items():\n",
    "        print(f\"{col}: {encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "487b61d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       0   42       2       0.00              1   \n",
       "1          608          2       0   41       1   83807.86              1   \n",
       "2          502          0       0   42       8  159660.80              3   \n",
       "3          699          0       0   39       1       0.00              2   \n",
       "4          850          2       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aef19381",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x,y,random_state=2 , test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8ea95279",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl' , 'wb') as file:\n",
    "    pickle.dump(ss , file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd3eff",
   "metadata": {},
   "source": [
    "ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9a67bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_tuner\\full_model_tuning\\tuner0.json\n",
      "\n",
      "Best Hyperparameters:\n",
      "---------------------\n",
      "Optimizer: adamw\n",
      "Learning Rate: 0.0017336359685746886\n",
      "Number of Layers: 2\n",
      "\n",
      "Layer 0:\n",
      "  Units: 128\n",
      "  Activation: hard_sigmoid\n",
      "  Dropout: 0.05\n",
      "  L2: 0.0\n",
      "\n",
      "Layer 1:\n",
      "  Units: 64\n",
      "  Activation: elu\n",
      "  Dropout: 0.05\n",
      "  L2: 0.007\n",
      "\n",
      "Training Configuration:\n",
      "Batch Size: 32\n",
      "Epochs: 100\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, PReLU, ELU, Activation\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tune batch_size and epochs HERE\n",
    "    # -----------------------------\n",
    "    # These need to be defined in build_model to be tracked\n",
    "    hp.Int('batch_size', 16, 128, step=16, default=32)\n",
    "    hp.Int('epochs', 10, 100, step=10, default=50)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tune number of hidden layers\n",
    "    # -----------------------------\n",
    "    num_layers = hp.Int(\"num_layers\", 1, 5, step=1)\n",
    "    for i in range(num_layers):\n",
    "        units = hp.Int(f\"units_{i}\", 16, 256, step=16)\n",
    "        activation = hp.Choice(\n",
    "            f\"activation_{i}\",\n",
    "            [\n",
    "                \"sigmoid\", \"tanh\", \"relu\", \"leaky_relu\", \"prelu\", \"elu\",\n",
    "                \"selu\", \"swish\", \"softmax\", \"gelu\", \"mish\", \"hard_swish\",\n",
    "                \"hard_sigmoid\", \"linear\", \"binary_step\"\n",
    "            ]\n",
    "        )\n",
    "        l2_reg = hp.Float(f\"l2_{i}\", 0.0, 0.01, step=0.001)\n",
    "\n",
    "        model.add(Dense(units=units, kernel_regularizer=regularizers.l2(l2_reg) if l2_reg > 0 else None))\n",
    "\n",
    "        # Apply activation\n",
    "        if activation == \"leaky_relu\":\n",
    "            model.add(LeakyReLU())\n",
    "        elif activation == \"prelu\":\n",
    "            model.add(PReLU())\n",
    "        elif activation == \"elu\":\n",
    "            model.add(ELU())\n",
    "        elif activation == \"swish\":\n",
    "            model.add(Activation(tf.nn.swish))\n",
    "        elif activation == \"gelu\":\n",
    "            model.add(Activation(tf.nn.gelu))\n",
    "        elif activation == \"mish\":\n",
    "            model.add(Activation(lambda x: x * tf.math.tanh(tf.math.softplus(x))))\n",
    "        elif activation == \"hard_swish\":\n",
    "            model.add(Activation(tf.nn.hard_swish))\n",
    "        elif activation == \"binary_step\":\n",
    "            model.add(Activation(lambda x: tf.where(x >= 0, 1.0, 0.0)))\n",
    "        else:\n",
    "            model.add(Activation(activation))\n",
    "\n",
    "        dropout_rate = hp.Float(f\"dropout_{i}\", 0.0, 0.5, step=0.05)\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tune optimizer\n",
    "    # -----------------------------\n",
    "    optimizer_name = hp.Choice(\n",
    "        \"optimizer\",\n",
    "        [\"sgd\", \"momentum\", \"nesterov\", \"adagrad\", \"adadelta\",\n",
    "         \"rmsprop\", \"adam\", \"adamax\", \"nadam\", \"adamw\"]\n",
    "    )\n",
    "    lr = hp.Float(\"learning_rate\", 1e-5, 1e-2, sampling=\"log\")\n",
    "\n",
    "    if optimizer_name == \"sgd\":\n",
    "        optimizer = optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer_name == \"momentum\":\n",
    "        optimizer = optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "    elif optimizer_name == \"nesterov\":\n",
    "        optimizer = optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True)\n",
    "    elif optimizer_name == \"adagrad\":\n",
    "        optimizer = optimizers.Adagrad(learning_rate=lr)\n",
    "    elif optimizer_name == \"adadelta\":\n",
    "        optimizer = optimizers.Adadelta(learning_rate=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = optimizers.RMSprop(learning_rate=lr)\n",
    "    elif optimizer_name == \"adam\":\n",
    "        optimizer = optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"adamax\":\n",
    "        optimizer = optimizers.Adamax(learning_rate=lr)\n",
    "    elif optimizer_name == \"nadam\":\n",
    "        optimizer = optimizers.Nadam(learning_rate=lr)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        optimizer = optimizers.AdamW(learning_rate=lr)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Custom tuner class to use batch_size and epochs from hyperparameters\n",
    "class MyTuner(kt.RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        # Extract batch_size and epochs from the trial's hyperparameters\n",
    "        kwargs['batch_size'] = trial.hyperparameters.get('batch_size')\n",
    "        kwargs['epochs'] = trial.hyperparameters.get('epochs')\n",
    "        return super(MyTuner, self).run_trial(trial, *args, **kwargs)\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize tuner\n",
    "# -----------------------------\n",
    "tuner = MyTuner(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=25,\n",
    "    directory=\"my_tuner\",\n",
    "    project_name=\"full_model_tuning\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Run hyperparameter search\n",
    "# -----------------------------\n",
    "tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Print best hyperparameters\n",
    "# -----------------------------\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(\"---------------------\")\n",
    "print(\"Optimizer:\", best_hp.get(\"optimizer\"))\n",
    "print(\"Learning Rate:\", best_hp.get(\"learning_rate\"))\n",
    "print(\"Number of Layers:\", best_hp.get(\"num_layers\"))\n",
    "\n",
    "for i in range(best_hp.get(\"num_layers\")):\n",
    "    print(f\"\\nLayer {i}:\")\n",
    "    print(\"  Units:\", best_hp.get(f\"units_{i}\"))\n",
    "    print(\"  Activation:\", best_hp.get(f\"activation_{i}\"))\n",
    "    print(\"  Dropout:\", best_hp.get(f\"dropout_{i}\"))\n",
    "    print(\"  L2:\", best_hp.get(f\"l2_{i}\"))\n",
    "\n",
    "print(\"\\nTraining Configuration:\")\n",
    "# Handle case where batch_size and epochs might not exist in saved tuner\n",
    "try:\n",
    "    print(\"Batch Size:\", best_hp.get(\"batch_size\"))\n",
    "except KeyError:\n",
    "    print(\"Batch Size: Not tuned (using default)\")\n",
    "\n",
    "try:\n",
    "    print(\"Epochs:\", best_hp.get(\"epochs\"))\n",
    "except KeyError:\n",
    "    print(\"Epochs: Not tuned (using default)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8815a2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │         \u001b[38;5;34m1,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_20 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │           \u001b[38;5;34m112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m28,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_21 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │        \u001b[38;5;34m57,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m225\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">88,321</span> (345.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m88,321\u001b[0m (345.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">88,321</span> (345.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m88,321\u001b[0m (345.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5721 - loss: 1.8374 - val_accuracy: 0.5995 - val_loss: 1.8363\n",
      "Epoch 2/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5771 - loss: 1.8357 - val_accuracy: 0.6170 - val_loss: 1.8342\n",
      "Epoch 3/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6068 - loss: 1.8323 - val_accuracy: 0.6355 - val_loss: 1.8321\n",
      "Epoch 4/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6087 - loss: 1.8314 - val_accuracy: 0.6520 - val_loss: 1.8299\n",
      "Epoch 5/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6109 - loss: 1.8300 - val_accuracy: 0.6720 - val_loss: 1.8277\n",
      "Epoch 6/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6324 - loss: 1.8272 - val_accuracy: 0.6845 - val_loss: 1.8256\n",
      "Epoch 7/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6419 - loss: 1.8259 - val_accuracy: 0.7055 - val_loss: 1.8234\n",
      "Epoch 8/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6494 - loss: 1.8229 - val_accuracy: 0.7190 - val_loss: 1.8212\n",
      "Epoch 9/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6670 - loss: 1.8208 - val_accuracy: 0.7365 - val_loss: 1.8190\n",
      "Epoch 10/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6726 - loss: 1.8192 - val_accuracy: 0.7435 - val_loss: 1.8169\n",
      "Epoch 11/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6739 - loss: 1.8175 - val_accuracy: 0.7505 - val_loss: 1.8148\n",
      "Epoch 12/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6923 - loss: 1.8152 - val_accuracy: 0.7560 - val_loss: 1.8127\n",
      "Epoch 13/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6977 - loss: 1.8134 - val_accuracy: 0.7670 - val_loss: 1.8106\n",
      "Epoch 14/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7141 - loss: 1.8108 - val_accuracy: 0.7710 - val_loss: 1.8086\n",
      "Epoch 15/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7099 - loss: 1.8097 - val_accuracy: 0.7765 - val_loss: 1.8066\n",
      "Epoch 16/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7205 - loss: 1.8078 - val_accuracy: 0.7760 - val_loss: 1.8046\n",
      "Epoch 17/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7261 - loss: 1.8059 - val_accuracy: 0.7800 - val_loss: 1.8027\n",
      "Epoch 18/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7305 - loss: 1.8045 - val_accuracy: 0.7850 - val_loss: 1.8008\n",
      "Epoch 19/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7374 - loss: 1.8023 - val_accuracy: 0.7860 - val_loss: 1.7989\n",
      "Epoch 20/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7410 - loss: 1.8006 - val_accuracy: 0.7895 - val_loss: 1.7971\n",
      "Epoch 21/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 1.7994 - val_accuracy: 0.7900 - val_loss: 1.7953\n",
      "Epoch 22/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7486 - loss: 1.7971 - val_accuracy: 0.7930 - val_loss: 1.7935\n",
      "Epoch 23/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7582 - loss: 1.7959 - val_accuracy: 0.7975 - val_loss: 1.7917\n",
      "Epoch 24/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7638 - loss: 1.7940 - val_accuracy: 0.7990 - val_loss: 1.7900\n",
      "Epoch 25/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7621 - loss: 1.7925 - val_accuracy: 0.7995 - val_loss: 1.7884\n",
      "Epoch 26/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7670 - loss: 1.7908 - val_accuracy: 0.8040 - val_loss: 1.7867\n",
      "Epoch 27/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7678 - loss: 1.7894 - val_accuracy: 0.8050 - val_loss: 1.7851\n",
      "Epoch 28/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7722 - loss: 1.7877 - val_accuracy: 0.8050 - val_loss: 1.7835\n",
      "Epoch 29/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7738 - loss: 1.7856 - val_accuracy: 0.8060 - val_loss: 1.7820\n",
      "Epoch 30/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7732 - loss: 1.7847 - val_accuracy: 0.8070 - val_loss: 1.7804\n",
      "Epoch 31/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7778 - loss: 1.7834 - val_accuracy: 0.8070 - val_loss: 1.7789\n",
      "Epoch 32/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7778 - loss: 1.7820 - val_accuracy: 0.8065 - val_loss: 1.7775\n",
      "Epoch 33/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7793 - loss: 1.7808 - val_accuracy: 0.8070 - val_loss: 1.7760\n",
      "Epoch 34/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7794 - loss: 1.7788 - val_accuracy: 0.8075 - val_loss: 1.7746\n",
      "Epoch 35/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7837 - loss: 1.7777 - val_accuracy: 0.8075 - val_loss: 1.7732\n",
      "Epoch 36/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7830 - loss: 1.7775 - val_accuracy: 0.8080 - val_loss: 1.7719\n",
      "Epoch 37/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7837 - loss: 1.7753 - val_accuracy: 0.8085 - val_loss: 1.7705\n",
      "Epoch 38/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7870 - loss: 1.7740 - val_accuracy: 0.8085 - val_loss: 1.7692\n",
      "Epoch 39/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7851 - loss: 1.7731 - val_accuracy: 0.8085 - val_loss: 1.7679\n",
      "Epoch 40/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7876 - loss: 1.7724 - val_accuracy: 0.8085 - val_loss: 1.7667\n",
      "Epoch 41/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7875 - loss: 1.7703 - val_accuracy: 0.8085 - val_loss: 1.7654\n",
      "Epoch 42/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7903 - loss: 1.7690 - val_accuracy: 0.8085 - val_loss: 1.7642\n",
      "Epoch 43/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7876 - loss: 1.7683 - val_accuracy: 0.8085 - val_loss: 1.7630\n",
      "Epoch 44/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7905 - loss: 1.7677 - val_accuracy: 0.8085 - val_loss: 1.7618\n",
      "Epoch 45/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7904 - loss: 1.7665 - val_accuracy: 0.8085 - val_loss: 1.7606\n",
      "Epoch 46/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7896 - loss: 1.7648 - val_accuracy: 0.8085 - val_loss: 1.7595\n",
      "Epoch 47/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7908 - loss: 1.7644 - val_accuracy: 0.8085 - val_loss: 1.7583\n",
      "Epoch 48/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7893 - loss: 1.7630 - val_accuracy: 0.8085 - val_loss: 1.7572\n",
      "Epoch 49/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7897 - loss: 1.7623 - val_accuracy: 0.8085 - val_loss: 1.7561\n",
      "Epoch 50/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7899 - loss: 1.7604 - val_accuracy: 0.8085 - val_loss: 1.7551\n",
      "Epoch 51/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7915 - loss: 1.7600 - val_accuracy: 0.8085 - val_loss: 1.7540\n",
      "Epoch 52/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7912 - loss: 1.7591 - val_accuracy: 0.8085 - val_loss: 1.7530\n",
      "Epoch 53/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7919 - loss: 1.7581 - val_accuracy: 0.8085 - val_loss: 1.7520\n",
      "Epoch 54/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7914 - loss: 1.7563 - val_accuracy: 0.8085 - val_loss: 1.7509\n",
      "Epoch 55/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7926 - loss: 1.7560 - val_accuracy: 0.8085 - val_loss: 1.7499\n",
      "Epoch 56/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7925 - loss: 1.7546 - val_accuracy: 0.8085 - val_loss: 1.7490\n",
      "Epoch 57/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7933 - loss: 1.7536 - val_accuracy: 0.8085 - val_loss: 1.7480\n",
      "Epoch 58/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7928 - loss: 1.7533 - val_accuracy: 0.8085 - val_loss: 1.7470\n",
      "Epoch 59/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7925 - loss: 1.7516 - val_accuracy: 0.8085 - val_loss: 1.7461\n",
      "Epoch 60/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7924 - loss: 1.7511 - val_accuracy: 0.8085 - val_loss: 1.7452\n",
      "Epoch 61/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7925 - loss: 1.7498 - val_accuracy: 0.8085 - val_loss: 1.7443\n",
      "Epoch 62/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7919 - loss: 1.7492 - val_accuracy: 0.8085 - val_loss: 1.7434\n",
      "Epoch 63/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 1.7479 - val_accuracy: 0.8085 - val_loss: 1.7425\n",
      "Epoch 64/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7930 - loss: 1.7478 - val_accuracy: 0.8085 - val_loss: 1.7416\n",
      "Epoch 65/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7925 - loss: 1.7469 - val_accuracy: 0.8085 - val_loss: 1.7407\n",
      "Epoch 66/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7929 - loss: 1.7467 - val_accuracy: 0.8085 - val_loss: 1.7398\n",
      "Epoch 67/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7929 - loss: 1.7446 - val_accuracy: 0.8085 - val_loss: 1.7390\n",
      "Epoch 68/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7933 - loss: 1.7442 - val_accuracy: 0.8085 - val_loss: 1.7382\n",
      "Epoch 69/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7925 - loss: 1.7435 - val_accuracy: 0.8085 - val_loss: 1.7373\n",
      "Epoch 70/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7926 - loss: 1.7428 - val_accuracy: 0.8085 - val_loss: 1.7365\n",
      "Epoch 71/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7933 - loss: 1.7421 - val_accuracy: 0.8085 - val_loss: 1.7357\n",
      "Epoch 72/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7929 - loss: 1.7410 - val_accuracy: 0.8085 - val_loss: 1.7349\n",
      "Epoch 73/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 1.7405 - val_accuracy: 0.8085 - val_loss: 1.7341\n",
      "Epoch 74/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 1.7404 - val_accuracy: 0.8085 - val_loss: 1.7333\n",
      "Epoch 75/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7930 - loss: 1.7384 - val_accuracy: 0.8085 - val_loss: 1.7325\n",
      "Epoch 76/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 1.7384 - val_accuracy: 0.8085 - val_loss: 1.7317\n",
      "Epoch 77/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7925 - loss: 1.7375 - val_accuracy: 0.8085 - val_loss: 1.7310\n",
      "Epoch 78/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7929 - loss: 1.7372 - val_accuracy: 0.8085 - val_loss: 1.7302\n",
      "Epoch 79/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7933 - loss: 1.7361 - val_accuracy: 0.8085 - val_loss: 1.7295\n",
      "Epoch 80/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7936 - loss: 1.7352 - val_accuracy: 0.8085 - val_loss: 1.7287\n",
      "Epoch 81/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7933 - loss: 1.7350 - val_accuracy: 0.8085 - val_loss: 1.7280\n",
      "Epoch 82/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7933 - loss: 1.7340 - val_accuracy: 0.8085 - val_loss: 1.7272\n",
      "Epoch 83/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7930 - loss: 1.7335 - val_accuracy: 0.8085 - val_loss: 1.7265\n",
      "Epoch 84/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7931 - loss: 1.7322 - val_accuracy: 0.8085 - val_loss: 1.7258\n",
      "Epoch 85/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 1.7312 - val_accuracy: 0.8085 - val_loss: 1.7251\n",
      "Epoch 86/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7933 - loss: 1.7309 - val_accuracy: 0.8085 - val_loss: 1.7244\n",
      "Epoch 87/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7931 - loss: 1.7308 - val_accuracy: 0.8085 - val_loss: 1.7237\n",
      "Epoch 88/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7933 - loss: 1.7300 - val_accuracy: 0.8085 - val_loss: 1.7230\n",
      "Epoch 89/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7931 - loss: 1.7284 - val_accuracy: 0.8085 - val_loss: 1.7223\n",
      "Epoch 90/90\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7934 - loss: 1.7284 - val_accuracy: 0.8085 - val_loss: 1.7216\n",
      "Restoring model weights from the end of the best epoch: 90.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2d4bdc82b50>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Best hyperparameters from tuner\n",
    "learning_rate = 0.00020770137026701493\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = Adadelta(learning_rate=learning_rate)\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(10,)))  # input layer with 8 features\n",
    "\n",
    "# Layer 0\n",
    "model.add(Dense(112,  kernel_regularizer=l2(0.009000000000000001)))\n",
    "model.add(PReLU())   \n",
    "model.add(Dropout(0.0))\n",
    "\n",
    "# Layer 1\n",
    "model.add(Dense(256,  kernel_regularizer=l2(0.003)))\n",
    "model.add(PReLU())   \n",
    "model.add(Dropout(0.4))\n",
    "# Layer 2\n",
    "model.add(Dense(224, activation='elu', kernel_regularizer=l2(0.004)))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='mean_squared_error', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# set up the TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Summary \n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',      # or 'val_accuracy' if you prefer\n",
    "    patience=20,             # wait for 20 epochs with no improvement\n",
    "    restore_best_weights=True, # restore the best weights after stopping\n",
    "    verbose=1\n",
    ")\n",
    "# Tensor Board callback\n",
    "tenserflow_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=90,              # maximum epochs\n",
    "    batch_size=80,            # or the best batch size from tuner\n",
    "   callbacks=[early_stop , tenserflow_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7bd11682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8d97d0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#let load TenserBoard Extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c037c4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6012 (pid 13252), started 0:37:24 ago. (Use '!kill 13252' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-89f7b876c178ce93\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-89f7b876c178ce93\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6012;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/fit/20251209-154539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "20b16fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load The Pickel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d23704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
