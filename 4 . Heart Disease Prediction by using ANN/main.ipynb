{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a50c890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65984ef5",
   "metadata": {},
   "source": [
    "DATA CLEANING AND PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12bcf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"heart.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "557e6441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"target\", data=data , hue=\"sex\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa683fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e12a35c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4395d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(\"target\", axis=1) \n",
    "y = data[\"target\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e741e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  \n",
       "0   2     3  \n",
       "1   0     3  \n",
       "2   0     3  \n",
       "3   1     3  \n",
       "4   3     2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "154f539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split our dataset\n",
    "x_train , x_test   , y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "#standardized our data \n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "594ea153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 13) (1025,)\n",
      "(820, 13) (820,)\n",
      "(205, 13) (205,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2516d2a6",
   "metadata": {},
   "source": [
    "Find THE BEST PARAMETER FOR OUR ANN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29bb7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.8390243649482727\n",
      "\n",
      "Best val_accuracy So Far: 0.8390243649482727\n",
      "Total elapsed time: 00h 03m 59s\n",
      "\n",
      "Best Hyperparameters:\n",
      "---------------------\n",
      "Optimizer: adamax\n",
      "Learning Rate: 0.005650457279796412\n",
      "Number of Layers: 1\n",
      "\n",
      "Layer 0:\n",
      "  Units: 112\n",
      "  Activation: tanh\n",
      "  Dropout: 0.1\n",
      "  L2: 0.003\n",
      "\n",
      "Training Configuration:\n",
      "Batch Size: 16\n",
      "Epochs: 50\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, PReLU, ELU, Activation\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tune batch_size and epochs HERE\n",
    "    # -----------------------------\n",
    "    # These need to be defined in build_model to be tracked\n",
    "    hp.Int('batch_size', 16, 128, step=16, default=32)\n",
    "    hp.Int('epochs', 10, 100, step=10, default=50)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tune number of hidden layers\n",
    "    # -----------------------------\n",
    "    num_layers = hp.Int(\"num_layers\", 1, 5, step=1)\n",
    "    for i in range(num_layers):\n",
    "        units = hp.Int(f\"units_{i}\", 16, 256, step=16)\n",
    "        activation = hp.Choice(\n",
    "            f\"activation_{i}\",\n",
    "            [\n",
    "                \"sigmoid\", \"tanh\", \"relu\", \"leaky_relu\", \"prelu\", \"elu\",\n",
    "                \"selu\", \"swish\", \"softmax\", \"gelu\", \"mish\", \"hard_swish\",\n",
    "                \"hard_sigmoid\", \"linear\", \"binary_step\"\n",
    "            ]\n",
    "        )\n",
    "        l2_reg = hp.Float(f\"l2_{i}\", 0.0, 0.01, step=0.001)\n",
    "\n",
    "        model.add(Dense(units=units, kernel_regularizer=regularizers.l2(l2_reg) if l2_reg > 0 else None))\n",
    "\n",
    "        # Apply activation\n",
    "        if activation == \"leaky_relu\":\n",
    "            model.add(LeakyReLU())\n",
    "        elif activation == \"prelu\":\n",
    "            model.add(PReLU())\n",
    "        elif activation == \"elu\":\n",
    "            model.add(ELU())\n",
    "        elif activation == \"swish\":\n",
    "            model.add(Activation(tf.nn.swish))\n",
    "        elif activation == \"gelu\":\n",
    "            model.add(Activation(tf.nn.gelu))\n",
    "        elif activation == \"mish\":\n",
    "            model.add(Activation(lambda x: x * tf.math.tanh(tf.math.softplus(x))))\n",
    "        elif activation == \"hard_swish\":\n",
    "            model.add(Activation(tf.nn.hard_swish))\n",
    "        elif activation == \"binary_step\":\n",
    "            model.add(Activation(lambda x: tf.where(x >= 0, 1.0, 0.0)))\n",
    "        else:\n",
    "            model.add(Activation(activation))\n",
    "\n",
    "        dropout_rate = hp.Float(f\"dropout_{i}\", 0.0, 0.5, step=0.05)\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tune optimizer\n",
    "    # -----------------------------\n",
    "    optimizer_name = hp.Choice(\n",
    "        \"optimizer\",\n",
    "        [\"sgd\", \"momentum\", \"nesterov\", \"adagrad\", \"adadelta\",\n",
    "         \"rmsprop\", \"adam\", \"adamax\", \"nadam\", \"adamw\"]\n",
    "    )\n",
    "    lr = hp.Float(\"learning_rate\", 1e-5, 1e-2, sampling=\"log\")\n",
    "\n",
    "    if optimizer_name == \"sgd\":\n",
    "        optimizer = optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer_name == \"momentum\":\n",
    "        optimizer = optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "    elif optimizer_name == \"nesterov\":\n",
    "        optimizer = optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True)\n",
    "    elif optimizer_name == \"adagrad\":\n",
    "        optimizer = optimizers.Adagrad(learning_rate=lr)\n",
    "    elif optimizer_name == \"adadelta\":\n",
    "        optimizer = optimizers.Adadelta(learning_rate=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = optimizers.RMSprop(learning_rate=lr)\n",
    "    elif optimizer_name == \"adam\":\n",
    "        optimizer = optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"adamax\":\n",
    "        optimizer = optimizers.Adamax(learning_rate=lr)\n",
    "    elif optimizer_name == \"nadam\":\n",
    "        optimizer = optimizers.Nadam(learning_rate=lr)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        optimizer = optimizers.AdamW(learning_rate=lr)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Custom tuner class to use batch_size and epochs from hyperparameters\n",
    "class MyTuner(kt.RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        # Extract batch_size and epochs from the trial's hyperparameters\n",
    "        kwargs['batch_size'] = trial.hyperparameters.get('batch_size')\n",
    "        kwargs['epochs'] = trial.hyperparameters.get('epochs')\n",
    "        return super(MyTuner, self).run_trial(trial, *args, **kwargs)\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize tuner\n",
    "# -----------------------------\n",
    "tuner = MyTuner(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=25,\n",
    "    directory=\"my_tuner\",\n",
    "    project_name=\"full_model_tuning\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Run hyperparameter search\n",
    "# -----------------------------\n",
    "tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Print best hyperparameters\n",
    "# -----------------------------\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(\"---------------------\")\n",
    "print(\"Optimizer:\", best_hp.get(\"optimizer\"))\n",
    "print(\"Learning Rate:\", best_hp.get(\"learning_rate\"))\n",
    "print(\"Number of Layers:\", best_hp.get(\"num_layers\"))\n",
    "\n",
    "for i in range(best_hp.get(\"num_layers\")):\n",
    "    print(f\"\\nLayer {i}:\")\n",
    "    print(\"  Units:\", best_hp.get(f\"units_{i}\"))\n",
    "    print(\"  Activation:\", best_hp.get(f\"activation_{i}\"))\n",
    "    print(\"  Dropout:\", best_hp.get(f\"dropout_{i}\"))\n",
    "    print(\"  L2:\", best_hp.get(f\"l2_{i}\"))\n",
    "\n",
    "print(\"\\nTraining Configuration:\")\n",
    "# Handle case where batch_size and epochs might not exist in saved tuner\n",
    "try:\n",
    "    print(\"Batch Size:\", best_hp.get(\"batch_size\"))\n",
    "except KeyError:\n",
    "    print(\"Batch Size: Not tuned (using default)\")\n",
    "\n",
    "try:\n",
    "    print(\"Epochs:\", best_hp.get(\"epochs\"))\n",
    "except KeyError:\n",
    "    print(\"Epochs: Not tuned (using default)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88aefb4",
   "metadata": {},
   "source": [
    "MAKE OUR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9913722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "457b9059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │           \u001b[38;5;34m448\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m113\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,129</span> (8.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,129\u001b[0m (8.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,905</span> (7.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,905\u001b[0m (7.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input , Dropout ,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#learning rate of our model\n",
    "learning_rate = 0.005650457279796412\n",
    "\n",
    "#Define optimizer \n",
    "optimizers = Adamax(learning_rate= learning_rate)\n",
    "\n",
    "#Build Model\n",
    "model = Sequential()\n",
    "model.add(Input(shape = (13,))) \n",
    "\n",
    "#Layer 0\n",
    "model.add(Dense(112, kernel_regularizer=l2(0.003)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "#compile model\n",
    "model.compile(optimizer = optimizers , loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "#summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8dd1f7",
   "metadata": {},
   "source": [
    "Trained our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd98e262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8110 - loss: 0.4731 - val_accuracy: 0.8098 - val_loss: 0.4900\n",
      "Epoch 2/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8634 - loss: 0.4122 - val_accuracy: 0.8098 - val_loss: 0.4913\n",
      "Epoch 3/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8683 - loss: 0.3989 - val_accuracy: 0.8244 - val_loss: 0.4722\n",
      "Epoch 4/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8720 - loss: 0.3729 - val_accuracy: 0.8195 - val_loss: 0.4643\n",
      "Epoch 5/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8707 - loss: 0.3745 - val_accuracy: 0.8244 - val_loss: 0.4581\n",
      "Epoch 6/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8744 - loss: 0.3587 - val_accuracy: 0.8293 - val_loss: 0.4433\n",
      "Epoch 7/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8927 - loss: 0.3313 - val_accuracy: 0.8293 - val_loss: 0.4414\n",
      "Epoch 8/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9049 - loss: 0.3108 - val_accuracy: 0.8390 - val_loss: 0.4209\n",
      "Epoch 9/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8963 - loss: 0.3138 - val_accuracy: 0.8341 - val_loss: 0.4117\n",
      "Epoch 10/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9061 - loss: 0.2974 - val_accuracy: 0.8439 - val_loss: 0.4073\n",
      "Epoch 11/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9024 - loss: 0.2843 - val_accuracy: 0.8488 - val_loss: 0.3943\n",
      "Epoch 12/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9024 - loss: 0.2806 - val_accuracy: 0.8537 - val_loss: 0.3775\n",
      "Epoch 13/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9256 - loss: 0.2642 - val_accuracy: 0.8634 - val_loss: 0.3609\n",
      "Epoch 14/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8963 - loss: 0.2805 - val_accuracy: 0.8780 - val_loss: 0.3432\n",
      "Epoch 15/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9341 - loss: 0.2402 - val_accuracy: 0.8488 - val_loss: 0.3363\n",
      "Epoch 16/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9232 - loss: 0.2435 - val_accuracy: 0.8585 - val_loss: 0.3411\n",
      "Epoch 17/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9293 - loss: 0.2309 - val_accuracy: 0.8878 - val_loss: 0.3048\n",
      "Epoch 18/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.2163 - val_accuracy: 0.8829 - val_loss: 0.3073\n",
      "Epoch 19/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.2120 - val_accuracy: 0.9073 - val_loss: 0.2784\n",
      "Epoch 20/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9463 - loss: 0.2116 - val_accuracy: 0.8878 - val_loss: 0.2772\n",
      "Epoch 21/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9341 - loss: 0.2004 - val_accuracy: 0.9122 - val_loss: 0.2602\n",
      "Epoch 22/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9463 - loss: 0.1955 - val_accuracy: 0.9220 - val_loss: 0.2574\n",
      "Epoch 23/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.1828 - val_accuracy: 0.9171 - val_loss: 0.2441\n",
      "Epoch 24/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9476 - loss: 0.1881 - val_accuracy: 0.9122 - val_loss: 0.2346\n",
      "Epoch 25/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.1760 - val_accuracy: 0.9122 - val_loss: 0.2320\n",
      "Epoch 26/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9585 - loss: 0.1630 - val_accuracy: 0.9073 - val_loss: 0.2079\n",
      "Epoch 27/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9390 - loss: 0.1843 - val_accuracy: 0.9268 - val_loss: 0.2072\n",
      "Epoch 28/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1590 - val_accuracy: 0.9024 - val_loss: 0.2287\n",
      "Epoch 29/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9585 - loss: 0.1538 - val_accuracy: 0.9171 - val_loss: 0.2048\n",
      "Epoch 30/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.1545 - val_accuracy: 0.9220 - val_loss: 0.1820\n",
      "Epoch 31/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9622 - loss: 0.1380 - val_accuracy: 0.9171 - val_loss: 0.1898\n",
      "Epoch 32/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9622 - loss: 0.1513 - val_accuracy: 0.9317 - val_loss: 0.1818\n",
      "Epoch 33/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.1403 - val_accuracy: 0.9415 - val_loss: 0.1742\n",
      "Epoch 34/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.1314 - val_accuracy: 0.9659 - val_loss: 0.1605\n",
      "Epoch 35/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9707 - loss: 0.1292 - val_accuracy: 0.9415 - val_loss: 0.1599\n",
      "Epoch 36/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9622 - loss: 0.1263 - val_accuracy: 0.9415 - val_loss: 0.1654\n",
      "Epoch 37/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9585 - loss: 0.1338 - val_accuracy: 0.9366 - val_loss: 0.1689\n",
      "Epoch 38/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9707 - loss: 0.1129 - val_accuracy: 0.9707 - val_loss: 0.1333\n",
      "Epoch 39/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9585 - loss: 0.1373 - val_accuracy: 0.9512 - val_loss: 0.1408\n",
      "Epoch 40/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.1127 - val_accuracy: 0.9707 - val_loss: 0.1392\n",
      "Epoch 41/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.1063 - val_accuracy: 0.9512 - val_loss: 0.1306\n",
      "Epoch 42/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9756 - loss: 0.1024 - val_accuracy: 0.9561 - val_loss: 0.1322\n",
      "Epoch 43/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9756 - loss: 0.1082 - val_accuracy: 0.9659 - val_loss: 0.1277\n",
      "Epoch 44/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9732 - loss: 0.1023 - val_accuracy: 0.9854 - val_loss: 0.1144\n",
      "Epoch 45/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9720 - loss: 0.1112 - val_accuracy: 0.9659 - val_loss: 0.1206\n",
      "Epoch 46/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9780 - loss: 0.0942 - val_accuracy: 0.9707 - val_loss: 0.1218\n",
      "Epoch 47/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.1050 - val_accuracy: 0.9707 - val_loss: 0.1244\n",
      "Epoch 48/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0790 - val_accuracy: 0.9707 - val_loss: 0.1106\n",
      "Epoch 49/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0808 - val_accuracy: 0.9854 - val_loss: 0.1094\n",
      "Epoch 50/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0866 - val_accuracy: 0.9854 - val_loss: 0.1082\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28dab609110>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=30,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1   \n",
    ")\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 50,\n",
    "    validation_data = (x_test,y_test),\n",
    "    callbacks = [early_stop]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d90f6b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "YES\n",
      "Probability: 0.99791974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ma516\\OneDrive\\Desktop\\Machine Learning projects\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_patient_Data = np.array([[\n",
    "71,0,0,112,149,0,1,125,0,1.6,1,0,2\n",
    "]])\n",
    "\n",
    "# If you used a scaler while training, apply it here:\n",
    "new_patient_Data = ss.transform(new_patient_Data)\n",
    "\n",
    "# Predict probability\n",
    "pred_prop = model.predict(new_patient_Data)[0][0]\n",
    "\n",
    "# Convert to class 0 or 1\n",
    "pred_class = 1 if pred_prop >= 0.5 else 0\n",
    "\n",
    "# Print YES / NO\n",
    "if pred_class == 1:\n",
    "    print(\"YES\")\n",
    "else:\n",
    "    print(\"NO\")\n",
    "\n",
    "print(\"Probability:\", pred_prop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24164db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"HeartDiseasePrediction.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e3b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
