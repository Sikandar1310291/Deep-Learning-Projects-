{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadcdf86-ed2e-4dc1-ae69-2b9363b38ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52664f4b-fe4d-48a5-9e88-d858110302ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear american teens question dutch person hear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nothing look forward lifei dont many reasons k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>music recommendations im looking expand playli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im done trying feel betterthe reason im still ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worried  year old girl subject domestic physic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  dear american teens question dutch person hear...      0\n",
       "1  nothing look forward lifei dont many reasons k...      1\n",
       "2  music recommendations im looking expand playli...      0\n",
       "3  im done trying feel betterthe reason im still ...      1\n",
       "4  worried  year old girl subject domestic physic...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"mental_health.csv\")\n",
    "data = data.iloc[:1500]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355b5996-39fa-46de-b894-86716c7736ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "def clean_text(text):\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
    "    text = re.sub(r'[•*|►▪●]', ' ', text)\n",
    "    text = re.sub(r'[\\r\\n\\t]', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "data['text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b668c38-9fb0-4426-99b9-8151561dc4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['text']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a69a18-364c-4ae4-b65a-48175487f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size : 13450\n",
      "max_len  1462\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#tokenize  \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x)\n",
    "# Sequencing\n",
    "sequence  = tokenizer.texts_to_sequences(x)\n",
    "#voacb_size \n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "print(\"vocab_size :\" , vocab_size)\n",
    "#maximun length\n",
    "max_len = max(len(seq) for seq in sequence)\n",
    "print(\"max_len \" , max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2744eba-6766-46c9-abb1-a352e65c8efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  189  835 1106]\n",
      " [   0    0    0 ...    3  600   72]\n",
      " [   0    0    0 ... 2785  800 6184]\n",
      " ...\n",
      " [   0    0    0 ...   28 1861  153]\n",
      " [   0    0    0 ... 4968    5  121]\n",
      " [   0    0    0 ...    3   11  372]]\n"
     ]
    }
   ],
   "source": [
    "# Padding Sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padding_Sequence_data = pad_sequences(sequence , maxlen=max_len)\n",
    "print(padding_Sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe80564-9537-4c32-b81a-e0cdc5444870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1462) (300, 1462) (1200,) (300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   58,    5,  121],\n",
       "       [   0,    0,    0, ..., 5177,   84,   79],\n",
       "       [   0,    0,    0, ...,   46,  137,   62],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  225,   20,  754],\n",
       "       [   0,    0,    0, ..., 8600,  392, 8601],\n",
       "       [   0,    0,    0, ..., 1410,  109,  444]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test  = train_test_split(padding_Sequence_data,y,random_state=2,test_size=0.2)\n",
    "print(x_train.shape , x_test.shape , y_train.shape , y_test.shape )\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b51447d-0096-45c1-8e6e-dcda136cdb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding , SimpleRNN , LSTM ,  GRU ,Bidirectional,   Dense  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3898c103-e619-4d57-89f1-50d4293971f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 462ms/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.6200 - val_loss: 0.6836\n",
      "Epoch 2/8\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 420ms/step - accuracy: 0.6853 - loss: 0.6785 - val_accuracy: 0.8233 - val_loss: 0.6555\n",
      "Epoch 3/8\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 437ms/step - accuracy: 0.8087 - loss: 0.6416 - val_accuracy: 0.9233 - val_loss: 0.5759\n",
      "Epoch 4/8\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 475ms/step - accuracy: 0.8507 - loss: 0.5342 - val_accuracy: 0.9600 - val_loss: 0.4203\n",
      "Epoch 5/8\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 488ms/step - accuracy: 0.9367 - loss: 0.3569 - val_accuracy: 0.9700 - val_loss: 0.2683\n",
      "Epoch 6/8\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 505ms/step - accuracy: 0.9740 - loss: 0.2315 - val_accuracy: 0.9933 - val_loss: 0.1627\n",
      "Epoch 7/8\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 497ms/step - accuracy: 0.9913 - loss: 0.1442 - val_accuracy: 0.9967 - val_loss: 0.1053\n",
      "Epoch 8/8\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 488ms/step - accuracy: 0.9967 - loss: 0.0944 - val_accuracy: 1.0000 - val_loss: 0.0716\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step\n",
      "Train Accuracy: 0.9993333333333333\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size  , output_dim = 25 ))\n",
    "model.add(Bidirectional(SimpleRNN(8 , activation=\"relu\" )))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\" , optimizer=\"Adam\" , metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(padding_Sequence_data,y,batch_size=32 ,epochs=8,validation_data=(x_test , y_test) )\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Predict on TRAIN data ---\n",
    "y_train_pred = model.predict(padding_Sequence_data)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
    "train_acc = accuracy_score(y, y_train_pred)\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "\n",
    "# --- Predict on TEST data ---\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = (y_test_pred > 0.5).astype(int)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d551d5a3-bc80-4f9e-92d8-e5d2050e0a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 643ms/step - accuracy: 0.5127 - loss: 0.6920 - val_accuracy: 0.4867 - val_loss: 0.6890\n",
      "Epoch 2/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 515ms/step - accuracy: 0.5100 - loss: 0.6833 - val_accuracy: 0.5067 - val_loss: 0.6714\n",
      "Epoch 3/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 541ms/step - accuracy: 0.5253 - loss: nan - val_accuracy: 0.4600 - val_loss: nan\n",
      "Epoch 4/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 490ms/step - accuracy: 0.5093 - loss: nan - val_accuracy: 0.4600 - val_loss: nan\n",
      "Epoch 5/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 467ms/step - accuracy: 0.5093 - loss: nan - val_accuracy: 0.4600 - val_loss: nan\n",
      "Epoch 6/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 480ms/step - accuracy: 0.5093 - loss: nan - val_accuracy: 0.4600 - val_loss: nan\n",
      "Epoch 7/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 540ms/step - accuracy: 0.5093 - loss: nan - val_accuracy: 0.4600 - val_loss: nan\n",
      "Epoch 8/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 517ms/step - accuracy: 0.5093 - loss: nan - val_accuracy: 0.4600 - val_loss: nan\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step\n",
      "Train Accuracy: 0.5093333333333333\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step\n",
      "Test Accuracy: 0.46\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size  , output_dim = 25 ))\n",
    "model.add(Bidirectional(LSTM(8 , activation=\"relu\" )))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\" , optimizer=\"Adam\" , metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(padding_Sequence_data,y,batch_size=64 ,epochs=8,validation_data=(x_test , y_test) )\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Predict on TRAIN data ---\n",
    "y_train_pred = model.predict(padding_Sequence_data)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
    "train_acc = accuracy_score(y, y_train_pred)\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "\n",
    "# --- Predict on TEST data ---\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = (y_test_pred > 0.5).astype(int)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bdf12e6-fe4d-4d70-a83f-5017bd706472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 362ms/step - accuracy: 0.5147 - loss: 0.6944 - val_accuracy: 0.7167 - val_loss: 0.6844\n",
      "Epoch 2/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 356ms/step - accuracy: 0.7400 - loss: 0.6801 - val_accuracy: 0.8233 - val_loss: 0.6689\n",
      "Epoch 3/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 374ms/step - accuracy: 0.8193 - loss: 0.6633 - val_accuracy: 0.8700 - val_loss: 0.6449\n",
      "Epoch 4/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 367ms/step - accuracy: 0.8733 - loss: 0.6345 - val_accuracy: 0.9067 - val_loss: 0.6026\n",
      "Epoch 5/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 374ms/step - accuracy: 0.9013 - loss: 0.5861 - val_accuracy: 0.9433 - val_loss: 0.5336\n",
      "Epoch 6/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9240 - loss: 0.5122 - val_accuracy: 0.9467 - val_loss: 0.4433\n",
      "Epoch 7/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 414ms/step - accuracy: 0.9380 - loss: 0.4161 - val_accuracy: 0.9600 - val_loss: 0.3399\n",
      "Epoch 8/8\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 411ms/step - accuracy: 0.9560 - loss: 0.3156 - val_accuracy: 0.9633 - val_loss: 0.2516\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n",
      "Train Accuracy: 0.9686666666666667\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Test Accuracy: 0.9633333333333334\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size  , output_dim = 25 ))\n",
    "model.add(Bidirectional(SimpleRNN(8 , activation=\"relu\" )))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\" , optimizer=\"Adam\" , metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(padding_Sequence_data,y,batch_size=64 ,epochs=8,validation_data=(x_test , y_test) )\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Predict on TRAIN data ---\n",
    "y_train_pred = model.predict(padding_Sequence_data)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
    "train_acc = accuracy_score(y, y_train_pred)\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "\n",
    "# --- Predict on TEST data ---\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = (y_test_pred > 0.5).astype(int)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f910e44-a94e-46ab-b6e1-2fdbb163d121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
